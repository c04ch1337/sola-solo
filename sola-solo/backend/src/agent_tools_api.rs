//! Agent tooling endpoints (hardware/sensory + other internal tools).
//!
//! ## Security Architecture
//!
//! This module implements a "Zero Trust" security model for Sola's autonomous tools:
//!
//! - **Level 0 (Secure):** Multi-factor identity confirmed within the last hour
//! - **Level 1 (Warning):** Single-modality match or presence scan pending
//! - **Level 2 (Alert):** Unknown face detected - lockdown mode enabled
//!
//! Critical tools (shell execution, file deletion, credential access) are gated
//! behind the `require_master_identity()` middleware.

use actix_web::{get, post, web, HttpResponse, Responder};
use serde::{Deserialize, Serialize};
use serde_json::json;
use std::sync::Arc;
use std::time::{Duration, SystemTime, UNIX_EPOCH};
use tokio::sync::RwLock;

use vector_kb::qdrant_backend::{QdrantConfig, QdrantVectorKB};

use crate::sensory::{
    extract_embedding_from_jpeg, detect_liveness, enroll_with_liveness,
    SensoryHub, SensoryStatus, LivenessResult,
};
use crate::security::{SecurityCoordinator, TelegramConfig, lock_workstation};

/// Application state containing shared sensory hub and security alerts.
pub struct AgentToolsState {
    pub sensory: Arc<SensoryHub>,
    pub security_alerts: Arc<RwLock<Vec<SecurityAlert>>>,
    pub security_state: Arc<RwLock<SecurityState>>,
    pub security_coordinator: Arc<SecurityCoordinator>,
}

impl AgentToolsState {
    /// Create a new AgentToolsState with the given sensory hub.
    pub fn new(sensory: Arc<SensoryHub>) -> Self {
        Self {
            sensory,
            security_alerts: Arc::new(RwLock::new(Vec::new())),
            security_state: Arc::new(RwLock::new(SecurityState::default())),
            security_coordinator: Arc::new(SecurityCoordinator::new()),
        }
    }

    /// Check if a critical tool can be accessed.
    ///
    /// This is the main entry point for identity-gated tool access.
    pub async fn check_tool_access(&self, tool_name: &str) -> IdentityGateResult {
        // Check if this is a critical tool
        if !CRITICAL_TOOLS.contains(&tool_name) {
            return IdentityGateResult {
                granted: true,
                security_level: self.security_state.read().await.level,
                reason: format!("Tool '{}' is not a critical tool - access granted", tool_name),
                identity: self.security_state.read().await.authenticated_identity.clone(),
            };
        }

        // For critical tools, require master identity
        let result = require_master_identity(&self.security_state).await;
        
        // Log access denial
        if !result.granted {
            let alert = SecurityAlert::tool_access_denied(tool_name);
            let mut alerts = self.security_alerts.write().await;
            alerts.push(alert);
            eprintln!(
                "[security] DENIED: Access to critical tool '{}' blocked - {}",
                tool_name, result.reason
            );
        }

        result
    }

    /// Handle an unknown face detection with full security response.
    ///
    /// This triggers:
    /// 1. Security state update to ALERT
    /// 2. Telegram notification (if configured)
    /// 3. Auto-lock timer start
    pub async fn handle_unknown_face_detected(&self, snapshot: Option<Vec<u8>>) {
        // Update security state
        {
            let mut state = self.security_state.write().await;
            state.record_unknown_face();
        }

        // Generate alert
        let alert = SecurityAlert::unknown_face();
        {
            let mut alerts = self.security_alerts.write().await;
            alerts.push(alert);
        }

        // Trigger security coordinator response (Telegram alert, etc.)
        self.security_coordinator.handle_unknown_face(snapshot).await;
    }

    /// Check and trigger auto-lock if conditions are met.
    ///
    /// Should be called periodically (e.g., every 10 seconds) when in alert state.
    pub async fn check_auto_lock(&self) -> bool {
        let state = self.security_state.read().await;
        
        // Only check if we're in alert state
        if state.level != security_levels::ALERT {
            // Reset alert state if we've dropped below alert
            self.security_coordinator.reset_alert_state().await;
            return false;
        }
        
        drop(state); // Release lock before potentially blocking operation
        
        // Check and trigger auto-lock
        self.security_coordinator.trigger_auto_lock_if_needed().await
    }
}

// ============================================================================
// Security Alert Types
// ============================================================================

/// A security alert generated by the sensory system.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SecurityAlert {
    /// Alert type (e.g., "unknown_face", "no_face_detected")
    pub alert_type: String,
    /// Human-readable description
    pub message: String,
    /// Priority level (1 = highest, 5 = lowest)
    pub priority: u8,
    /// Timestamp in milliseconds since UNIX epoch
    pub timestamp_ms: u64,
    /// Whether the alert has been acknowledged
    pub acknowledged: bool,
}

impl SecurityAlert {
    /// Create a new high-priority security alert for an unknown face.
    pub fn unknown_face() -> Self {
        Self {
            alert_type: "unknown_face".to_string(),
            message: "Unknown person detected in front of PC".to_string(),
            priority: 1,
            timestamp_ms: SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .map(|d| d.as_millis() as u64)
                .unwrap_or(0),
            acknowledged: false,
        }
    }

    /// Create a new alert for no face detected.
    pub fn no_face_detected() -> Self {
        Self {
            alert_type: "no_face_detected".to_string(),
            message: "No face detected during presence scan".to_string(),
            priority: 3,
            timestamp_ms: SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .map(|d| d.as_millis() as u64)
                .unwrap_or(0),
            acknowledged: false,
        }
    }

    /// Create a new alert for liveness check failure.
    pub fn liveness_failed(reason: &str) -> Self {
        Self {
            alert_type: "liveness_failed".to_string(),
            message: format!("Liveness check failed: {}", reason),
            priority: 1,
            timestamp_ms: SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .map(|d| d.as_millis() as u64)
                .unwrap_or(0),
            acknowledged: false,
        }
    }

    /// Create a new alert for consecutive scan failures.
    pub fn consecutive_scan_failures(count: u32) -> Self {
        Self {
            alert_type: "consecutive_scan_failures".to_string(),
            message: format!("{} consecutive presence scans failed - security elevated", count),
            priority: 1,
            timestamp_ms: SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .map(|d| d.as_millis() as u64)
                .unwrap_or(0),
            acknowledged: false,
        }
    }

    /// Create a new alert for tool access denial.
    pub fn tool_access_denied(tool_name: &str) -> Self {
        Self {
            alert_type: "tool_access_denied".to_string(),
            message: format!("Access denied to critical tool '{}': Potential intruder detected", tool_name),
            priority: 2,
            timestamp_ms: SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .map(|d| d.as_millis() as u64)
                .unwrap_or(0),
            acknowledged: false,
        }
    }
}

// ============================================================================
// Security Level Management
// ============================================================================

/// Security level constants.
pub mod security_levels {
    /// Level 0: Multi-factor identity confirmed within the last hour
    pub const SECURE: u8 = 0;
    /// Level 1: Single-modality match or presence scan pending
    pub const WARNING: u8 = 1;
    /// Level 2: Unknown face detected - lockdown mode
    pub const ALERT: u8 = 2;
}

/// Persistent security state for the agent.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SecurityState {
    /// Current security level (0 = secure, 1 = warning, 2 = alert)
    pub level: u8,
    /// Timestamp of last successful multi-factor authentication
    pub last_mfa_timestamp_ms: Option<u64>,
    /// Timestamp of last successful single-factor authentication
    pub last_single_factor_timestamp_ms: Option<u64>,
    /// Label of the authenticated identity
    pub authenticated_identity: Option<String>,
    /// Whether multi-factor authentication was used
    pub is_multi_factor: bool,
    /// Number of consecutive failed presence scans
    pub consecutive_scan_failures: u32,
    /// Maximum allowed consecutive failures before lockdown
    pub max_consecutive_failures: u32,
    /// Duration in milliseconds before MFA expires (default: 1 hour)
    pub mfa_expiry_ms: u64,
    /// Duration in milliseconds before single-factor expires (default: 15 minutes)
    pub single_factor_expiry_ms: u64,
}

impl Default for SecurityState {
    fn default() -> Self {
        Self {
            level: security_levels::WARNING,
            last_mfa_timestamp_ms: None,
            last_single_factor_timestamp_ms: None,
            authenticated_identity: None,
            is_multi_factor: false,
            consecutive_scan_failures: 0,
            max_consecutive_failures: 3,
            mfa_expiry_ms: 60 * 60 * 1000, // 1 hour
            single_factor_expiry_ms: 15 * 60 * 1000, // 15 minutes
        }
    }
}

impl SecurityState {
    /// Check if the current authentication is still valid.
    pub fn is_authenticated(&self) -> bool {
        let now = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .map(|d| d.as_millis() as u64)
            .unwrap_or(0);

        // Check MFA first (longer validity)
        if let Some(mfa_ts) = self.last_mfa_timestamp_ms {
            if now - mfa_ts < self.mfa_expiry_ms {
                return true;
            }
        }

        // Check single-factor (shorter validity)
        if let Some(sf_ts) = self.last_single_factor_timestamp_ms {
            if now - sf_ts < self.single_factor_expiry_ms {
                return true;
            }
        }

        false
    }

    /// Update security level based on current state.
    pub fn update_level(&mut self) {
        let now = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .map(|d| d.as_millis() as u64)
            .unwrap_or(0);

        // Check for consecutive failures first
        if self.consecutive_scan_failures >= self.max_consecutive_failures {
            self.level = security_levels::ALERT;
            return;
        }

        // Check MFA validity
        if let Some(mfa_ts) = self.last_mfa_timestamp_ms {
            if now - mfa_ts < self.mfa_expiry_ms {
                self.level = security_levels::SECURE;
                return;
            }
        }

        // Check single-factor validity
        if let Some(sf_ts) = self.last_single_factor_timestamp_ms {
            if now - sf_ts < self.single_factor_expiry_ms {
                self.level = security_levels::WARNING;
                return;
            }
        }

        // No valid authentication
        self.level = security_levels::WARNING;
    }

    /// Record a successful multi-factor authentication.
    pub fn record_mfa_success(&mut self, identity: String) {
        let now = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .map(|d| d.as_millis() as u64)
            .unwrap_or(0);

        self.last_mfa_timestamp_ms = Some(now);
        self.last_single_factor_timestamp_ms = Some(now);
        self.authenticated_identity = Some(identity);
        self.is_multi_factor = true;
        self.consecutive_scan_failures = 0;
        self.level = security_levels::SECURE;
    }

    /// Record a successful single-factor authentication.
    pub fn record_single_factor_success(&mut self, identity: String) {
        let now = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .map(|d| d.as_millis() as u64)
            .unwrap_or(0);

        self.last_single_factor_timestamp_ms = Some(now);
        self.authenticated_identity = Some(identity);
        self.is_multi_factor = false;
        self.consecutive_scan_failures = 0;
        self.update_level();
    }

    /// Record a failed presence scan.
    pub fn record_scan_failure(&mut self) {
        self.consecutive_scan_failures += 1;
        if self.consecutive_scan_failures >= self.max_consecutive_failures {
            self.level = security_levels::ALERT;
        }
    }

    /// Record an unknown face detection (immediate lockdown).
    pub fn record_unknown_face(&mut self) {
        self.level = security_levels::ALERT;
        self.authenticated_identity = None;
        self.is_multi_factor = false;
    }

    /// Reset security state after manual acknowledgment.
    pub fn reset_to_warning(&mut self) {
        self.level = security_levels::WARNING;
        self.consecutive_scan_failures = 0;
    }
}

/// Result of identity gate check.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct IdentityGateResult {
    /// Whether access is granted
    pub granted: bool,
    /// Current security level
    pub security_level: u8,
    /// Reason for the decision
    pub reason: String,
    /// Authenticated identity (if any)
    pub identity: Option<String>,
}

/// Check if the current security state allows access to critical tools.
///
/// This is the "require_master_identity()" middleware function.
/// Returns an IdentityGateResult indicating whether access is granted.
pub async fn require_master_identity(
    security_state: &RwLock<SecurityState>,
) -> IdentityGateResult {
    let state = security_state.read().await;
    
    // Level 2 (Alert) always denies access
    if state.level == security_levels::ALERT {
        return IdentityGateResult {
            granted: false,
            security_level: state.level,
            reason: "Access Denied: Potential Intruder Detected. Security level is ALERT.".to_string(),
            identity: None,
        };
    }

    // Level 0 (Secure) with valid MFA grants full access
    if state.level == security_levels::SECURE && state.is_authenticated() {
        return IdentityGateResult {
            granted: true,
            security_level: state.level,
            reason: "Access granted: Multi-factor authentication valid".to_string(),
            identity: state.authenticated_identity.clone(),
        };
    }

    // Level 1 (Warning) with valid single-factor grants limited access
    if state.level == security_levels::WARNING && state.is_authenticated() {
        return IdentityGateResult {
            granted: true,
            security_level: state.level,
            reason: "Access granted: Single-factor authentication valid (limited privileges)".to_string(),
            identity: state.authenticated_identity.clone(),
        };
    }

    // No valid authentication
    IdentityGateResult {
        granted: false,
        security_level: state.level,
        reason: "Access Denied: No valid authentication. Please verify identity.".to_string(),
        identity: None,
    }
}

/// List of critical tools that require master identity verification.
pub const CRITICAL_TOOLS: &[&str] = &[
    "shell_execute",
    "file_delete",
    "credential_access",
    "system_modify",
    "database_delete",
    "network_config",
    "security_override",
];

/// Security status response.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SecurityStatus {
    /// Current security level (0 = secure, 1 = warning, 2 = alert)
    pub level: u8,
    /// Human-readable status message
    pub message: String,
    /// Number of unacknowledged alerts
    pub unacknowledged_alerts: usize,
    /// Recent alerts (last 10)
    pub recent_alerts: Vec<SecurityAlert>,
    /// Last presence scan result
    pub last_presence_scan: Option<PresenceScanResult>,
}

/// Result of a presence scan.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PresenceScanResult {
    /// Identified label (None if unknown)
    pub label: Option<String>,
    /// Confidence score (0.0 to 1.0)
    pub confidence: f32,
    /// Whether multi-factor authentication was used
    pub multi_factor: bool,
    /// Timestamp of the scan
    pub timestamp_ms: u64,
}

// ============================================================================
// Enrollment Types
// ============================================================================

#[derive(Debug, Deserialize)]
pub struct SensoryEnrollRequest {
    /// Identity label (e.g. "jamey"). Required for multi-factor enrollment.
    pub label: String,
    /// Optional metadata (free-form).
    pub metadata: Option<serde_json::Value>,
    /// Optional override for Qdrant URL.
    pub qdrant_url: Option<String>,
}

/// Response from multi-factor enrollment.
#[derive(Debug, Serialize)]
pub struct EnrollmentResult {
    pub ok: bool,
    pub label: String,
    pub face_embedding_id: Option<String>,
    pub voice_embedding_id: Option<String>,
    pub frames_captured: usize,
    pub audio_duration_secs: f32,
    pub message: String,
    /// Liveness detection result (if enabled)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub liveness: Option<LivenessResult>,
}

/// Request for enrollment with liveness detection.
#[derive(Debug, Deserialize)]
pub struct SensoryEnrollWithLivenessRequest {
    /// Identity label (e.g. "jamey"). Required for multi-factor enrollment.
    pub label: String,
    /// Optional metadata (free-form).
    pub metadata: Option<serde_json::Value>,
    /// Optional override for Qdrant URL.
    pub qdrant_url: Option<String>,
    /// Whether to require liveness detection (default: true)
    #[serde(default = "default_require_liveness")]
    pub require_liveness: bool,
}

fn default_require_liveness() -> bool {
    true
}

// ============================================================================
// Endpoints
// ============================================================================

/// Multi-factor biometric enrollment endpoint (legacy, without liveness).
///
/// Captures 5 camera frames and 5 seconds of audio, then stores both
/// face and voice embeddings in Qdrant's `sola_identities` collection.
#[post("/api/agent/sensory/enroll")]
pub async fn sensory_enroll(
    state: web::Data<AgentToolsState>,
    req: web::Json<SensoryEnrollRequest>,
) -> impl Responder {
    let label = req.label.clone();
    if label.is_empty() {
        return HttpResponse::BadRequest().json(json!({
            "error": "label is required for enrollment"
        }));
    }

    let url = req
        .qdrant_url
        .clone()
        .or_else(|| std::env::var("QDRANT_URL").ok())
        .unwrap_or_else(|| "http://localhost:6333".to_string());

    let kb = match QdrantVectorKB::new(QdrantConfig {
        url,
        collection_name: None,
        embedding_dim: None,
    })
    .await
    {
        Ok(kb) => kb,
        Err(e) => {
            return HttpResponse::BadGateway().json(json!({
                "error": "failed to connect to qdrant",
                "detail": e.to_string()
            }))
        }
    };

    // Start audio capture
    state.sensory.start_audio_capture().await;

    // Capture 5 frames over ~2.5 seconds
    let mut face_embeddings: Vec<Vec<f32>> = Vec::new();
    let mut captured_frames: Vec<Vec<u8>> = Vec::new();
    for _ in 0..5 {
        tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
        let frame = state.sensory.latest_frame().await;
        if !frame.jpeg_data.is_empty() {
            captured_frames.push(frame.jpeg_data.clone());
            if let Ok(Some(emb)) = extract_embedding_from_jpeg(&frame.jpeg_data) {
                face_embeddings.push(emb.embedding);
            }
        }
    }

    // Wait for 5 seconds total of audio (we already waited 2.5s for frames)
    tokio::time::sleep(tokio::time::Duration::from_millis(2500)).await;

    // Stop audio capture and extract voiceprint
    state.sensory.stop_audio_capture().await;
    let voiceprint = state.sensory.extract_voiceprint_from_capture().await;

    let metadata = req.metadata.clone().unwrap_or_else(|| json!({}));

    // Store face embedding (average of captured frames)
    let face_embedding_id = if !face_embeddings.is_empty() {
        // Average the face embeddings
        let mut avg_embedding = vec![0.0f32; 512];
        for emb in &face_embeddings {
            for (i, val) in emb.iter().enumerate() {
                if i < 512 {
                    avg_embedding[i] += val;
                }
            }
        }
        let count = face_embeddings.len() as f32;
        for val in &mut avg_embedding {
            *val /= count;
        }

        // L2 normalize
        let norm: f32 = avg_embedding.iter().map(|x| x * x).sum::<f32>().sqrt();
        if norm > 0.0 {
            for val in &mut avg_embedding {
                *val /= norm;
            }
        }

        let mut face_metadata = metadata.clone();
        if let Some(obj) = face_metadata.as_object_mut() {
            obj.insert("biometric_type".to_string(), json!("face"));
            obj.insert("frames_captured".to_string(), json!(face_embeddings.len()));
        }

        match kb
            .upsert_identity_embedding(Some(label.clone()), avg_embedding, face_metadata)
            .await
        {
            Ok(id) => Some(id),
            Err(e) => {
                eprintln!("[enroll] Failed to store face embedding: {}", e);
                None
            }
        }
    } else {
        None
    };

    // Store voice embedding
    let voice_embedding_id = if voiceprint.confidence > 0.0 {
        let mut voice_metadata = metadata.clone();
        if let Some(obj) = voice_metadata.as_object_mut() {
            obj.insert("biometric_type".to_string(), json!("voice"));
            obj.insert("duration_secs".to_string(), json!(voiceprint.duration_secs));
        }

        match kb
            .upsert_identity_embedding(
                Some(format!("{}_voice", label)),
                voiceprint.embedding.clone(),
                voice_metadata,
            )
            .await
        {
            Ok(id) => Some(id),
            Err(e) => {
                eprintln!("[enroll] Failed to store voice embedding: {}", e);
                None
            }
        }
    } else {
        None
    };

    let result = EnrollmentResult {
        ok: face_embedding_id.is_some() || voice_embedding_id.is_some(),
        label: label.clone(),
        face_embedding_id,
        voice_embedding_id,
        frames_captured: face_embeddings.len(),
        audio_duration_secs: voiceprint.duration_secs,
        message: format!(
            "Enrolled {} with {} face frames and {:.1}s of audio",
            label,
            face_embeddings.len(),
            voiceprint.duration_secs
        ),
        liveness: None,
    };

    HttpResponse::Ok().json(result)
}

/// Multi-factor biometric enrollment with liveness detection (anti-spoofing).
///
/// This endpoint requires the user to demonstrate liveness (blink or head movement)
/// during the capture process. If liveness is not detected, enrollment fails.
///
/// Captures 5 camera frames and 5 seconds of audio, verifies liveness, then stores
/// both face and voice embeddings in Qdrant's `sola_identities` collection.
#[post("/api/agent/sensory/enroll_secure")]
pub async fn sensory_enroll_secure(
    state: web::Data<AgentToolsState>,
    req: web::Json<SensoryEnrollWithLivenessRequest>,
) -> impl Responder {
    let label = req.label.clone();
    if label.is_empty() {
        return HttpResponse::BadRequest().json(json!({
            "error": "label is required for enrollment"
        }));
    }

    let url = req
        .qdrant_url
        .clone()
        .or_else(|| std::env::var("QDRANT_URL").ok())
        .unwrap_or_else(|| "http://localhost:6333".to_string());

    let kb = match QdrantVectorKB::new(QdrantConfig {
        url,
        collection_name: None,
        embedding_dim: None,
    })
    .await
    {
        Ok(kb) => kb,
        Err(e) => {
            return HttpResponse::BadGateway().json(json!({
                "error": "failed to connect to qdrant",
                "detail": e.to_string()
            }))
        }
    };

    // Start audio capture
    state.sensory.start_audio_capture().await;

    // Capture 5 frames over ~2.5 seconds (for liveness detection)
    let mut captured_frames: Vec<Vec<u8>> = Vec::new();
    let mut face_embeddings: Vec<Vec<f32>> = Vec::new();
    
    eprintln!("[enroll_secure] Starting capture - please blink or move your head");
    
    for i in 0..5 {
        tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;
        let frame = state.sensory.latest_frame().await;
        if !frame.jpeg_data.is_empty() {
            captured_frames.push(frame.jpeg_data.clone());
            if let Ok(Some(emb)) = extract_embedding_from_jpeg(&frame.jpeg_data) {
                face_embeddings.push(emb.embedding);
            }
        }
        eprintln!("[enroll_secure] Captured frame {}/5", i + 1);
    }

    // Wait for 5 seconds total of audio (we already waited 2.5s for frames)
    tokio::time::sleep(tokio::time::Duration::from_millis(2500)).await;

    // Stop audio capture and extract voiceprint
    state.sensory.stop_audio_capture().await;
    let voiceprint = state.sensory.extract_voiceprint_from_capture().await;

    // Perform liveness detection
    let liveness = detect_liveness(&captured_frames);
    eprintln!("[enroll_secure] Liveness result: {:?}", liveness);

    // If liveness is required and not detected, fail enrollment
    if req.require_liveness && !liveness.is_live {
        // Generate security alert
        let alert = SecurityAlert::liveness_failed(&liveness.message);
        let mut alerts = state.security_alerts.write().await;
        alerts.push(alert);
        
        return HttpResponse::Forbidden().json(json!({
            "error": "Liveness check failed - possible spoofing attempt",
            "detail": liveness.message,
            "liveness": liveness,
            "hint": "Please blink or move your head during enrollment"
        }));
    }

    let metadata = req.metadata.clone().unwrap_or_else(|| json!({}));

    // Store face embedding (average of captured frames)
    let face_embedding_id = if !face_embeddings.is_empty() {
        // Average the face embeddings
        let mut avg_embedding = vec![0.0f32; 512];
        for emb in &face_embeddings {
            for (i, val) in emb.iter().enumerate() {
                if i < 512 {
                    avg_embedding[i] += val;
                }
            }
        }
        let count = face_embeddings.len() as f32;
        for val in &mut avg_embedding {
            *val /= count;
        }

        // L2 normalize
        let norm: f32 = avg_embedding.iter().map(|x| x * x).sum::<f32>().sqrt();
        if norm > 0.0 {
            for val in &mut avg_embedding {
                *val /= norm;
            }
        }

        let mut face_metadata = metadata.clone();
        if let Some(obj) = face_metadata.as_object_mut() {
            obj.insert("biometric_type".to_string(), json!("face"));
            obj.insert("frames_captured".to_string(), json!(face_embeddings.len()));
            obj.insert("liveness_verified".to_string(), json!(liveness.is_live));
            obj.insert("liveness_confidence".to_string(), json!(liveness.confidence));
        }

        match kb
            .upsert_identity_embedding(Some(label.clone()), avg_embedding, face_metadata)
            .await
        {
            Ok(id) => Some(id),
            Err(e) => {
                eprintln!("[enroll_secure] Failed to store face embedding: {}", e);
                None
            }
        }
    } else {
        None
    };

    // Store voice embedding
    let voice_embedding_id = if voiceprint.confidence > 0.0 {
        let mut voice_metadata = metadata.clone();
        if let Some(obj) = voice_metadata.as_object_mut() {
            obj.insert("biometric_type".to_string(), json!("voice"));
            obj.insert("duration_secs".to_string(), json!(voiceprint.duration_secs));
        }

        match kb
            .upsert_identity_embedding(
                Some(format!("{}_voice", label)),
                voiceprint.embedding.clone(),
                voice_metadata,
            )
            .await
        {
            Ok(id) => Some(id),
            Err(e) => {
                eprintln!("[enroll_secure] Failed to store voice embedding: {}", e);
                None
            }
        }
    } else {
        None
    };

    let result = EnrollmentResult {
        ok: face_embedding_id.is_some() || voice_embedding_id.is_some(),
        label: label.clone(),
        face_embedding_id,
        voice_embedding_id,
        frames_captured: face_embeddings.len(),
        audio_duration_secs: voiceprint.duration_secs,
        message: format!(
            "Securely enrolled {} with {} face frames, {:.1}s of audio, and liveness verification",
            label,
            face_embeddings.len(),
            voiceprint.duration_secs
        ),
        liveness: Some(liveness),
    };

    HttpResponse::Ok().json(result)
}

/// Get the current security status.
///
/// Returns the current security level, recent alerts, and last presence scan result.
#[get("/api/agent/security/status")]
pub async fn security_status(state: web::Data<AgentToolsState>) -> impl Responder {
    let alerts = state.security_alerts.read().await;
    let unacknowledged = alerts.iter().filter(|a| !a.acknowledged).count();

    // Determine security level based on alerts
    let level = if alerts.iter().any(|a| !a.acknowledged && a.priority == 1) {
        2 // Alert - high priority unacknowledged
    } else if unacknowledged > 0 {
        1 // Warning - some unacknowledged alerts
    } else {
        0 // Secure
    };

    let message = match level {
        0 => "All clear - no security concerns".to_string(),
        1 => format!("{} unacknowledged alert(s)", unacknowledged),
        _ => "ALERT: Unknown person detected!".to_string(),
    };

    // Get last 10 alerts
    let recent_alerts: Vec<SecurityAlert> = alerts.iter().rev().take(10).cloned().collect();

    let status = SecurityStatus {
        level,
        message,
        unacknowledged_alerts: unacknowledged,
        recent_alerts,
        last_presence_scan: None, // TODO: Track last scan result
    };

    HttpResponse::Ok().json(status)
}

/// Acknowledge all security alerts.
#[post("/api/agent/security/acknowledge")]
pub async fn security_acknowledge(state: web::Data<AgentToolsState>) -> impl Responder {
    let mut alerts = state.security_alerts.write().await;
    for alert in alerts.iter_mut() {
        alert.acknowledged = true;
    }
    HttpResponse::Ok().json(json!({
        "ok": true,
        "acknowledged": alerts.len()
    }))
}

/// Clear all security alerts.
#[post("/api/agent/security/clear")]
pub async fn security_clear(state: web::Data<AgentToolsState>) -> impl Responder {
    let mut alerts = state.security_alerts.write().await;
    let count = alerts.len();
    alerts.clear();
    HttpResponse::Ok().json(json!({
        "ok": true,
        "cleared": count
    }))
}

/// Get the current status of all sensory subsystems.
///
/// Returns camera and audio pipeline status including running state,
/// configuration, and any recent errors.
#[get("/api/agent/sensory/status")]
pub async fn sensory_status(state: web::Data<AgentToolsState>) -> impl Responder {
    let status: SensoryStatus = state.sensory.status().await;
    HttpResponse::Ok().json(status)
}

/// Get the latest camera frame as JPEG.
///
/// Returns the most recent frame captured by the camera worker.
/// If no frame is available, returns a 204 No Content response.
#[get("/api/agent/sensory/snapshot")]
pub async fn sensory_snapshot(state: web::Data<AgentToolsState>) -> impl Responder {
    let frame = state.sensory.latest_frame().await;

    if frame.jpeg_data.is_empty() {
        return HttpResponse::NoContent().finish();
    }

    HttpResponse::Ok()
        .content_type("image/jpeg")
        .insert_header(("X-Frame-Timestamp", frame.timestamp_ms.to_string()))
        .body(frame.jpeg_data)
}

/// Get the latest voice activity detection result.
///
/// Returns whether speech was detected and the timestamp.
#[get("/api/agent/sensory/vad")]
pub async fn sensory_vad(state: web::Data<AgentToolsState>) -> impl Responder {
    let vad = state.sensory.latest_vad().await;
    HttpResponse::Ok().json(vad)
}

/// Start all sensory subsystems.
#[post("/api/agent/sensory/start")]
pub async fn sensory_start(state: web::Data<AgentToolsState>) -> impl Responder {
    state.sensory.start_all().await;
    HttpResponse::Ok().json(json!({"ok": true, "message": "sensory subsystems started"}))
}

/// Stop all sensory subsystems.
#[post("/api/agent/sensory/stop")]
pub async fn sensory_stop(state: web::Data<AgentToolsState>) -> impl Responder {
    state.sensory.stop_all().await;
    HttpResponse::Ok().json(json!({"ok": true, "message": "sensory subsystems stopped"}))
}

/// Attempt to identify who is in front of the PC.
///
/// Uses face recognition to match against known identities in Qdrant.
/// If an unknown face is detected, a security alert is generated and
/// the security state is updated to ALERT level.
#[get("/api/agent/sensory/identify")]
pub async fn sensory_identify(state: web::Data<AgentToolsState>) -> impl Responder {
    match state.sensory.identify_presence().await {
        Ok(identity) => {
            let mut security_state = state.security_state.write().await;
            
            // Check if this is an unknown face
            if identity.label.is_none() && identity.confidence > 0.0 {
                // Face detected but not recognized - LOCKDOWN
                security_state.record_unknown_face();
                eprintln!("[security] ALERT: Unknown person detected! Security level elevated to ALERT.");
                
                // Release lock before async operation
                drop(security_state);
                
                // Trigger full security response (Telegram alert, auto-lock timer, etc.)
                // Try to capture a snapshot for the alert
                let frame = state.sensory.latest_frame().await;
                let snapshot = if !frame.jpeg_data.is_empty() {
                    Some(frame.jpeg_data)
                } else {
                    None
                };
                state.handle_unknown_face_detected(snapshot).await;
                
                // Re-acquire lock for response
                let security_state = state.security_state.read().await;
                
                HttpResponse::Ok().json(json!({
                    "identity": identity,
                    "security_level": security_state.level,
                    "authenticated": security_state.is_authenticated(),
                    "alert": "unknown_face_detected",
                    "telegram_notified": state.security_coordinator.telegram_enabled(),
                }))
            } else if let Some(ref label) = identity.label {
                // Known identity detected
                if identity.confidence >= 1.0 {
                    // Multi-factor authenticated (confidence = 1.0)
                    security_state.record_mfa_success(label.clone());
                    eprintln!("[security] Multi-factor authentication successful for: {}", label);
                } else if identity.confidence > 0.7 {
                    // Single-factor match
                    security_state.record_single_factor_success(label.clone());
                    eprintln!("[security] Single-factor authentication for: {} (confidence: {:.2})", label, identity.confidence);
                }
                
                HttpResponse::Ok().json(json!({
                    "identity": identity,
                    "security_level": security_state.level,
                    "authenticated": security_state.is_authenticated(),
                }))
            } else {
                // No face detected - record as scan failure
                security_state.record_scan_failure();
                
                // Check if we've hit the failure threshold
                if security_state.consecutive_scan_failures >= security_state.max_consecutive_failures {
                    let alert = SecurityAlert::consecutive_scan_failures(security_state.consecutive_scan_failures);
                    let mut alerts = state.security_alerts.write().await;
                    alerts.push(alert);
                    eprintln!("[security] {} consecutive scan failures - security elevated to ALERT", 
                        security_state.consecutive_scan_failures);
                }
                
                HttpResponse::Ok().json(json!({
                    "identity": identity,
                    "security_level": security_state.level,
                    "authenticated": security_state.is_authenticated(),
                }))
            }
        }
        Err(e) => HttpResponse::InternalServerError().json(json!({
            "error": "identification failed",
            "detail": e.to_string()
        })),
    }
}

/// Check if a tool can be accessed based on current security state.
///
/// This endpoint is used by the agent to verify access before executing
/// critical tools like shell commands or file deletion.
#[derive(Debug, Deserialize)]
pub struct ToolAccessRequest {
    pub tool_name: String,
}

#[post("/api/agent/security/check_access")]
pub async fn security_check_access(
    state: web::Data<AgentToolsState>,
    req: web::Json<ToolAccessRequest>,
) -> impl Responder {
    let result = state.check_tool_access(&req.tool_name).await;
    
    if result.granted {
        HttpResponse::Ok().json(result)
    } else {
        HttpResponse::Forbidden().json(result)
    }
}

/// Get the detailed security state (for debugging/admin).
#[get("/api/agent/security/state")]
pub async fn security_state_detail(state: web::Data<AgentToolsState>) -> impl Responder {
    let security_state = state.security_state.read().await;
    HttpResponse::Ok().json(security_state.clone())
}

/// Reset security state to WARNING level (requires manual intervention).
#[post("/api/agent/security/reset")]
pub async fn security_reset(state: web::Data<AgentToolsState>) -> impl Responder {
    let mut security_state = state.security_state.write().await;
    security_state.reset_to_warning();
    
    // Also acknowledge all alerts
    let mut alerts = state.security_alerts.write().await;
    for alert in alerts.iter_mut() {
        alert.acknowledged = true;
    }
    
    HttpResponse::Ok().json(json!({
        "ok": true,
        "message": "Security state reset to WARNING level",
        "new_level": security_state.level,
    }))
}

/// List critical tools that require identity verification.
#[get("/api/agent/security/critical_tools")]
pub async fn security_critical_tools() -> impl Responder {
    HttpResponse::Ok().json(json!({
        "critical_tools": CRITICAL_TOOLS,
        "description": "These tools require master identity verification before execution",
    }))
}

// ============================================================================
// Windows Notification System
// ============================================================================

/// Request for sending a security notification.
#[derive(Debug, Deserialize)]
pub struct SecurityNotifyRequest {
    /// Alert type (e.g., "unknown_face", "liveness_failed")
    pub alert_type: String,
    /// Human-readable message
    pub message: String,
    /// Optional JPEG snapshot data (base64 encoded)
    pub snapshot_base64: Option<String>,
}

/// Send a Windows notification for security alerts.
///
/// This endpoint sends a local Windows toast notification when an
/// unknown face is detected or other security events occur.
#[cfg(all(windows, feature = "notifications"))]
#[post("/api/agent/security/notify")]
pub async fn security_notify(
    state: web::Data<AgentToolsState>,
    req: web::Json<SecurityNotifyRequest>,
) -> impl Responder {
    use winrt_notification::{Duration, Sound, Toast};
    
    let title = match req.alert_type.as_str() {
        "unknown_face" => "âš ï¸ SECURITY ALERT: Unknown Person Detected",
        "liveness_failed" => "âš ï¸ SECURITY ALERT: Liveness Check Failed",
        "consecutive_scan_failures" => "âš ï¸ SECURITY WARNING: Multiple Scan Failures",
        "tool_access_denied" => "ðŸ”’ Access Denied: Critical Tool Blocked",
        _ => "ðŸ”” Sola Security Notification",
    };
    
    // Create the toast notification
    let result = Toast::new(Toast::POWERSHELL_APP_ID)
        .title(title)
        .text1(&req.message)
        .sound(Some(Sound::Default))
        .duration(Duration::Long)
        .show();
    
    match result {
        Ok(_) => {
            eprintln!("[security] Windows notification sent: {}", req.alert_type);
            
            // Also store the alert
            let alert = SecurityAlert {
                alert_type: req.alert_type.clone(),
                message: req.message.clone(),
                priority: if req.alert_type == "unknown_face" { 1 } else { 2 },
                timestamp_ms: SystemTime::now()
                    .duration_since(UNIX_EPOCH)
                    .map(|d| d.as_millis() as u64)
                    .unwrap_or(0),
                acknowledged: false,
            };
            let mut alerts = state.security_alerts.write().await;
            alerts.push(alert);
            
            // Save snapshot if provided
            if let Some(ref snapshot_b64) = req.snapshot_base64 {
                if let Ok(snapshot_data) = base64_decode(snapshot_b64) {
                    let timestamp = SystemTime::now()
                        .duration_since(UNIX_EPOCH)
                        .map(|d| d.as_millis())
                        .unwrap_or(0);
                    let snapshot_path = format!("security_snapshots/intruder_{}.jpg", timestamp);
                    
                    // Ensure directory exists
                    let _ = std::fs::create_dir_all("security_snapshots");
                    
                    if let Err(e) = std::fs::write(&snapshot_path, &snapshot_data) {
                        eprintln!("[security] Failed to save snapshot: {}", e);
                    } else {
                        eprintln!("[security] Snapshot saved to: {}", snapshot_path);
                    }
                }
            }
            
            HttpResponse::Ok().json(json!({
                "ok": true,
                "message": "Notification sent successfully",
            }))
        }
        Err(e) => {
            eprintln!("[security] Failed to send Windows notification: {:?}", e);
            HttpResponse::InternalServerError().json(json!({
                "ok": false,
                "error": "Failed to send notification",
                "detail": format!("{:?}", e),
            }))
        }
    }
}

/// Send a security notification (stub for non-Windows or when notifications feature is disabled).
#[cfg(not(all(windows, feature = "notifications")))]
#[post("/api/agent/security/notify")]
pub async fn security_notify(
    state: web::Data<AgentToolsState>,
    req: web::Json<SecurityNotifyRequest>,
) -> impl Responder {
    eprintln!("[security] Notification requested (notifications feature not enabled): {}", req.alert_type);
    
    // Still store the alert even if we can't send a notification
    let alert = SecurityAlert {
        alert_type: req.alert_type.clone(),
        message: req.message.clone(),
        priority: if req.alert_type == "unknown_face" { 1 } else { 2 },
        timestamp_ms: SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .map(|d| d.as_millis() as u64)
            .unwrap_or(0),
        acknowledged: false,
    };
    let mut alerts = state.security_alerts.write().await;
    alerts.push(alert);
    
    HttpResponse::Ok().json(json!({
        "ok": true,
        "message": "Alert stored (notifications feature not enabled)",
        "notification_sent": false,
    }))
}

/// Helper function to decode base64 data.
fn base64_decode(input: &str) -> Result<Vec<u8>, String> {
    // Simple base64 decoding
    use std::collections::HashMap;
    
    let alphabet = "ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/";
    let mut decode_map: HashMap<char, u8> = HashMap::new();
    for (i, c) in alphabet.chars().enumerate() {
        decode_map.insert(c, i as u8);
    }
    
    let input = input.trim_end_matches('=');
    let mut output = Vec::new();
    let mut buffer: u32 = 0;
    let mut bits_collected = 0;
    
    for c in input.chars() {
        if c.is_whitespace() {
            continue;
        }
        let val = decode_map.get(&c).ok_or_else(|| format!("Invalid base64 character: {}", c))?;
        buffer = (buffer << 6) | (*val as u32);
        bits_collected += 6;
        
        while bits_collected >= 8 {
            bits_collected -= 8;
            output.push((buffer >> bits_collected) as u8);
            buffer &= (1 << bits_collected) - 1;
        }
    }
    
    Ok(output)
}

// =============================================================================
// SECURITY LOCK & TELEGRAM ENDPOINTS
// =============================================================================

/// Lock the Windows workstation immediately.
///
/// This is a CRITICAL tool that requires master identity verification.
/// It calls the Windows `LockWorkStation()` API to lock the screen.
///
/// ## Security
/// - Requires security level 0 (Secure) or 1 (Warning)
/// - Blocked if security level is 2 (Alert) - prevents intruder from locking you out
/// - Sends Telegram notification if configured
#[post("/api/agent/security/lock")]
pub async fn security_lock_workstation(
    state: web::Data<AgentToolsState>,
) -> impl Responder {
    // Check tool access - this is a critical tool
    let access = state.check_tool_access("lock_workstation").await;
    if !access.granted {
        return HttpResponse::Forbidden().json(json!({
            "error": "access_denied",
            "reason": access.reason,
            "security_level": access.security_level,
        }));
    }

    // Attempt to lock the workstation
    #[cfg(feature = "system-lock")]
    {
        match lock_workstation() {
            Ok(()) => {
                eprintln!("[security] Workstation locked successfully");
                
                // Send Telegram notification
                state.security_coordinator.notify_lock_triggered("manual_request").await;
                
                HttpResponse::Ok().json(json!({
                    "success": true,
                    "message": "Workstation locked",
                    "telegram_notified": state.security_coordinator.telegram_enabled(),
                }))
            }
            Err(e) => {
                eprintln!("[security] Failed to lock workstation: {}", e);
                HttpResponse::InternalServerError().json(json!({
                    "error": "lock_failed",
                    "detail": e.to_string(),
                }))
            }
        }
    }

    #[cfg(not(feature = "system-lock"))]
    {
        HttpResponse::NotImplemented().json(json!({
            "error": "feature_disabled",
            "message": "System lock feature is not enabled. Compile with --features system-lock",
        }))
    }
}

/// Test Telegram integration by sending a test message.
///
/// This endpoint verifies that Telegram alerts are properly configured
/// and can reach the configured chat.
#[post("/api/agent/security/telegram/test")]
pub async fn security_telegram_test(
    state: web::Data<AgentToolsState>,
) -> impl Responder {
    if !state.security_coordinator.telegram_enabled() {
        return HttpResponse::BadRequest().json(json!({
            "error": "telegram_not_configured",
            "message": "Telegram is not configured. Set TELEGRAM_BOT_TOKEN and TELEGRAM_CHAT_ID environment variables.",
        }));
    }

    match state.security_coordinator.send_test_message().await {
        Ok(()) => HttpResponse::Ok().json(json!({
            "success": true,
            "message": "Test message sent to Telegram",
        })),
        Err(e) => HttpResponse::InternalServerError().json(json!({
            "error": "telegram_send_failed",
            "detail": e.to_string(),
        })),
    }
}

/// Get Telegram configuration status.
#[get("/api/agent/security/telegram/status")]
pub async fn security_telegram_status(
    state: web::Data<AgentToolsState>,
) -> impl Responder {
    HttpResponse::Ok().json(json!({
        "enabled": state.security_coordinator.telegram_enabled(),
        "chat_id_configured": state.security_coordinator.telegram_chat_configured(),
    }))
}

/// Check and trigger auto-lock if conditions are met.
///
/// This endpoint should be called periodically (e.g., every 10 seconds)
/// by the scheduler when the system is in alert state.
#[post("/api/agent/security/check_auto_lock")]
pub async fn security_check_auto_lock(
    state: web::Data<AgentToolsState>,
) -> impl Responder {
    let triggered = state.check_auto_lock().await;
    
    HttpResponse::Ok().json(json!({
        "auto_lock_triggered": triggered,
        "security_level": state.security_state.read().await.level,
    }))
}

/// Configure agent tools routes.
///
/// Note: The caller must provide `AgentToolsState` via `app_data()` before
/// calling this configuration function.
pub fn configure(cfg: &mut web::ServiceConfig) {
    cfg.service(sensory_enroll)
        .service(sensory_enroll_secure)
        .service(sensory_status)
        .service(sensory_snapshot)
        .service(sensory_vad)
        .service(sensory_start)
        .service(sensory_stop)
        .service(sensory_identify)
        .service(security_status)
        .service(security_acknowledge)
        .service(security_clear)
        .service(security_check_access)
        .service(security_state_detail)
        .service(security_reset)
        .service(security_critical_tools)
        .service(security_notify)
        // New security hardening endpoints
        .service(security_lock_workstation)
        .service(security_telegram_test)
        .service(security_telegram_status)
        .service(security_check_auto_lock);
}
